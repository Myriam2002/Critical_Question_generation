model,runs,mean_punctuation,mean_punctuation_with_llm,mean_llm_labeled_percentage
RL_trial_4,1,0.5175438596491228,0.7631578947368421,25.438596491228072
RL,9,0.5370370370370371,0.743664717348928,25.57404940445876
Qwen_Qwen2.5-72B-Instruct,6,0.706140350877193,0.837719298245614,13.157894736842104
Qwen_Qwen2.5-3B-Instruct,4,0.37280701754385964,0.5526315789473685,30.866580866580865
meta-llama_Llama-3.2-3B-Instruct,5,0.6456140350877193,0.8421052631578949,20.52631578947368
deepseek-reasoner,4,0.618421052631579,0.8662280701754387,25.43859649122807
Qwen_Qwen2.5-7B-Instruct,4,0.6206140350877194,0.8070175438596492,22.587719298245613
Qwen_Qwen2.5-14B-Instruct,5,0.6543859649122807,0.836842105263158,18.59649122807017
deepseek-ai_DeepSeek-V3-0324,2,0.6842105263157896,0.855263157894737,17.105263157894736
RL_trial_3,1,0.5263157894736841,0.7807017543859651,27.192982456140353
meta-llama_Llama-3.3-70B-Instruct,4,0.2302631578947368,0.2565789473684211,9.480676328502415
RL_trial_2,4,0.5460526315789473,0.7653508771929826,25.0
meta-llama_Llama-3.1-8B-Instruct,7,0.6904761904761905,0.8433583959899751,15.538847117794486
meta-llama_Meta-Llama-3.1-405B-Instruct,4,0.7763157894736842,0.8530701754385965,8.114035087719298
RL_trial_4_3,1,0.5877192982456142,0.868421052631579,29.82456140350877
meta-llama_Meta-Llama-3.1-8B-Instruct,2,0.6842105263157894,0.8333333333333335,15.350877192982455
RL_trial_4_4,1,0.6754385964912282,0.8333333333333335,18.421052631578945
RL_trial_4_2,1,0.5789473684210528,0.8070175438596493,23.684210526315788
RL_trial_4_5,1,0.6228070175438598,0.780701754385965,19.298245614035086
