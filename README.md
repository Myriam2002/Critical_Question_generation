
# 🧠 Critical Questions Generation 
This repository contains the setup for our **Critical Question Generation** project for argumentative texts, combining **ML**, **LLM**, and **Reinforcement Learning** approaches.  
Developed by:  
**Alaa Elsetohy · Sama Hadhoud · Mariam Barakat**

## 📚 Project Description

This project aims to automatically generate and evaluate critical questions over argumentative texts.  
We experiment with:

- Machine Learning classifiers
- LLM-based generation and feedback loops
- Reinforcement Learning fine-tuning
- Theory-based approaches using argumentation schemes
- Logical fallacy detection baselines

---

## 🛠️ Setup (Placeholder)

You can prepare your environment while waiting for the finalized code.

```bash
git clone https://github.com/YOUR_USERNAME/YOUR_REPOSITORY.git
cd YOUR_REPOSITORY
python3 -m venv venv
source venv/bin/activate     # Linux / Mac
venv\Scripts\activate      # Windows
pip install -r requirements.txt
```

_(requirements.txt will be added soon.)_

---

## 🚀 How to Run (Placeholder)

Scripts will be finalized soon. Expected entry points:

| File                          | Description                                |
|-------------------------------|--------------------------------------------|
| `generate_questions.py`       | Generate initial critical questions        |
| `evaluate_questions.py`       | Evaluate generated questions               |
| `ml_classifier_training.py`   | Train ML model to classify question quality |
| `agentic_pipeline.py`         | ML + LLM feedback agentic loop             |
| `rl_finetuning.py`            | Reinforcement Learning fine-tuning         |
| `argumentation_scheme_mapper.py` | Map texts to argumentation schemes       |
| `logical_fallacy_detector.py` | Logical fallacy detection baseline         |

✅ Scripts will be updated once finalized.

---

## 📂 Repository Structure (Expected)

```bash
├── data/                    # Dataset (argumentative texts and labeled questions)
├── models/                  # Saved ML/RL models
├── outputs/                 # Generated outputs and evaluation reports
├── scripts/                 # Main project scripts
├── requirements.txt         # Project dependencies (coming soon)
└── README.md                # Project overview (this file)
```

